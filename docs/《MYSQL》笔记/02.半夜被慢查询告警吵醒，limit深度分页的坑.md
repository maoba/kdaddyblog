---
title: 半夜被慢查询告警吵醒，limit深度分页的坑
date: 2024-06-24 22:26:12
permalink: /pages/e5ab47/
categories:
  - 《MYSQL》笔记
tags:
  - mysql索引
author: 
  name: 老猫
  link: https://github.com/maoba
---
## 故事
梅雨季，闷热的夜，令人窒息，窗外一道道闪电划破漆黑的夜幕，小猫塞着耳机听着恐怖小说，辗转反侧，终于睡意来了，然而挨千刀的手机早不振晚不振，偏偏这个时候振动了一下，一个激灵，没有按捺住对内容的好奇，点开了短信，卧槽？告警信息，原来是负责的服务出现慢查询了。小猫想起来，今天在下班之前上线了一个版本，由于新增了一个业务字段，所以小猫写了相关的刷数据的接口，在下班之前调用开始刷历史数据。

考虑到表的数据量比较大，一次性把数据全部读取出来然后在内存里面去刷新数据肯定是不现实的，所以小猫采用了分页查询的方式依次根据条件查询出结果，然后进行表数据的重置。没想到的是，数据量太大，分页的深度越来越深，渐渐地，慢查询也就暴露出来了。

![慢查询告警](https://cdn.ktdaddy.com/mysql/limit/01.jpg)

强迫症小猫瞬间睡意全无，翻起来打开电脑开始解决问题。

那么为什么用使用limit之后会出现慢查询呢？接下来老猫和大家一起来剖析一下吧。

## limit分页为什么会变慢？
在解释为什么慢之前，咱们来重现一下小猫的慢查询场景。咱们从实际的例子推进。

### 做个小实验
假设我们有一张这样的业务表，商品Product表。具体的建表语句如下：
```
CREATE TABLE `Product` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `type` tinyint(3) unsigned NOT NULL DEFAULT '1' ,
  `spuCode` varchar(50) NOT NULL DEFAULT '' ,
  `spuName` varchar(100) NOT NULL DEFAULT '' ,
  `spuTitle` varchar(300) NOT NULL DEFAULT '' ,
  `channelId` bigint(20) unsigned NOT NULL DEFAULT '0',
  `sellerId` bigint(20) unsigned NOT NULL DEFAULT '0'
  `mallSpuCode` varchar(32) NOT NULL DEFAULT '',
  `originCategoryId` bigint(20) unsigned NOT NULL DEFAULT '0' ,
  `originCategoryName` varchar(50) NOT NULL DEFAULT '' ,
  `marketPrice` decimal(10,2) unsigned NOT NULL DEFAULT '0.00',
  `status` tinyint(3) unsigned NOT NULL DEFAULT '1' ,
  `isDeleted` tinyint(3) unsigned NOT NULL DEFAULT '0',
  `timeCreated` datetime(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3),
  `timeModified` datetime(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) ,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_spuCode` (`spuCode`,`channelId`,`sellerId`),
  KEY `idx_timeCreated` (`timeCreated`),
  KEY `idx_spuName` (`spuName`),
  KEY `idx_channelId_originCategory` (`channelId`,`originCategoryId`,`originCategoryName`) USING BTREE,
  KEY `idx_sellerId` (`sellerId`)
) ENGINE=InnoDB AUTO_INCREMENT=12553120 DEFAULT CHARSET=utf8mb4 COMMENT='商品表'
```

从上述建表语句中我们发现timeCreated走普通索引。
接下来我们根据创建时间来执行一下分页查询：

当为浅分页的时候，如下：
```sql
select * from Product where timeCreated > "2020-09-12 13:34:20" limit 0,10
```
此时执行的时间为：
"executeTimeMillis":1

当调整分页查询为深度分页之后，如下：
```sql
select * from Product where timeCreated > "2020-09-12 13:34:20" limit 10000000,10
```
此时深度分页的查询时间为：
"executeTimeMillis":27499

此时看到这里，小猫的场景已经重现了，此时深度分页的查询已经非常耗时。

### 剖析一下原因
### 简单回顾一下普通索引和聚簇索引
我们来回顾一下普通索引和聚簇索引（也有人叫做聚集索引）的关系。

大家可能都知道Mysql底层用的数据结构是B+tree（如果有不知道的伙伴可以自己了解一下为什么mysql底层是B+tree）,B+tree索引其实可以分为两大类，一类是聚簇索引，另外一类是非聚集索引（即普通索引）。

（1）聚簇索引：InnoDB存储表是索引组织表，聚簇索引就是一种索引组织形式，聚簇索引叶子节点存放表中所有行数据记录的信息，所以经常会说索引即数据，数据即索引。当然这个是针对聚簇索引。

![聚簇索引](https://cdn.ktdaddy.com/mysql/limit/02.png)

由图可知在执行查询的时候，从根节点开始共经历了3次查询即可找到真实数据。倘若没有聚簇索引的话，就需要在磁盘上进行逐个扫描，直至找到数据为止。显然，索引会加快查询速度，但是在写入数据的时候，由于需要维护这颗B+树，因此在写入过程中性能也会下降。

（2）普通索引：普通索引在叶子节点并不包含所有行的数据记录，只是会在叶子节点存本身的键值和主键的值，在检索数据的时候，通过普通索引子节点上的主键来获取想要找到的行数据记录。

![普通索引](https://cdn.ktdaddy.com/mysql/limit/03.png)

由图可知流程，首先从非聚簇索引开始寻找聚簇索引，找到非聚簇索引上的聚簇索引后，就会到聚簇索引的B+树上进行查询，通过聚簇索引B+树找到完整的数据。该过程比较专业的叫法也被称为“回表”。

### 看一下实际深度分页执行过程
有了以上的知识基础我们再来回过头看一下上述深度分页SQL的执行过程。
上述的查询语句中idx_timeCreated显然是普通索引，咱们结合上述的知识储备点，其深度分页的执行就可以拆分为如下步骤：

1、通过普通索引idx_timeCreated，过滤timeCreated，找到满足条件的记录ID；

2、通过ID，回到主键索引树，找到满足记录的行，然后取出展示的列（回表）；

3、扫描满足条件的10000010行，然后扔掉前10000000行，返回。

结合看一下执行计划：

![执行计划](https://cdn.ktdaddy.com/mysql/limit/04.png)

原因其实很清晰了：
显然，导致这句SQL速度慢的问题出现在第3步。第三步中发生了10000010次回表，这前面的10000000条数据完全对本次查询没有意义，但是却占据了绝大部分的查询时间。

再深入一点从底层存储来看，数据库表中行数据、索引都是以文件的形式存储到磁盘(硬盘)上的，而硬盘的速度相对来说要慢很多，存储引擎运行sql语句时，需要访问硬盘查询文件，然后返回数据给服务层。当返回的数据越多时，访问磁盘的次数就越多，就会越耗时。


## 替换limit分页的一些方案。
上述我们其实已经搞清楚深度分页慢的原因了，总结为“无用回表次数过多”。

那怎么优化呢？相信大家应该都已经知道了，其核心当然是减少无用回表次数了。

有哪些方式可以帮助我们减少无用回表次数呢？

### 子查询法
思路：如果把查询条件，转移回到主键索引树，那就不就可以减少回表次数了。
所以，咱们将实际的SQL改成下面这种形式：
```sql
select * FROM Product where id >= (select p.id from Product p where p.timeCreated > "2020-09-12 13:34:20" limit 10000000, 1) LIMIT 10;
```
测试一下执行时间：
"executeTimeMillis":2534

我们可以明显地看到相比之前的27499简直就是质的飞跃。
